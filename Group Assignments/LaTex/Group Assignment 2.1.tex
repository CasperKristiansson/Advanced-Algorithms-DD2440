\documentclass{article}
\usepackage{cite}
\usepackage{graphicx} % Required for inserting images
\usepackage{mathtools}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{xcolor}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\usepackage{enumitem}

\SetKwInOut{KwData}{Input}
\SetKwInOut{KwResult}{Output}
\SetKw{KwOr}{or}

\title{Group Assignment 2.1}
\author{Niv Adam, David Kaufmann, Casper Kristiansson, Nicole Wijkman}
\date{\today}

\begin{document}

\maketitle

\section{E-Level Problem (2.1)}
We want to find an estimate $\hat{p}$ for the probability that the coin shows heads. From the task, we know that the true probability is $p$.
Let us define a set of random variables $Y_i=\{0,1\}$ where $Y_i$ represents the $i$-th coin flip and $Y_i = 1$ if the coin shows heads. Let further $\hat{p} = \frac{1}{k}\sum_i Y_i$ be the average of these random variables. The $Y_i$ are by definition uniform and independent. By this definition, $\hat{p}$ is an estimator of $p$.
In the next section, we define an algorithm that calculates $\hat{p}$ such that $P(|\hat{p}-p|\leq \epsilon)\geq 1-\delta$. The algorithm is based on the fact, that by flipping a coin often enough $\hat{p}$ converges to $p$. By defining the number of flips $k$ dependent on $\epsilon$ and $\delta$ we can guarantee the requested probability bounds. We assume $\delta\in(0,1)$ and $\epsilon > 0$.



\subsection{Algorithm}

\begin{algorithm}\label{alg:longestPath}
\caption{Estimate Coin Bias}
\DontPrintSemicolon

\SetKwFunction{FMain}{CoinBias}
\SetKwProg{Fn}{Function}{:}{}
\Fn{\FMain{$\epsilon$, $\delta$}}{
   $k = \lceil -\frac{\ln(\delta/2)}{2\epsilon^2} \rceil$\

   $numberOfHeads = 0$

   \For{$i\leftarrow 1$ \KwTo $k$} {
       $isHead = FlipCoin()$;

       \If{$isHead$}{
            $numberOfHeads = numberOfHeads + 1$\;
        }
   }

   \KwRet $numberOfHeads / k$\;
}

\end{algorithm}


\subsection{Correctness}
First, we can convince ourselves that $\mathbb{E}[Y_i]=p$ since $p$ is the true probability that the coin shows heads. 
Since $\hat{p}$ is the average of all $Y_i$ by linearity of expectation we get $\mathbb{E}[\hat{p}]=p$. Since all $Y_i$ are independent and uniformly at random Chernoff bounds can be applied.
This gives the following two probabilities:
$$P(\hat{p} \leq p-\epsilon) \leq e^{-2k\epsilon^2}$$
$$P(\hat{p}\geq p+\epsilon) \leq e^{-2k\epsilon^2}$$
We define a bad Event $B=$``$\hat{p} \leq p-\epsilon$ or $\hat{p}\geq p+\epsilon$'' and can calculate its probability using union bound
$$P(B) \leq P(\hat{p} \leq p-\epsilon) + P(\hat{p}\geq p+\epsilon) \leq 2e^{-2k\epsilon^2}$$
From the problem statement and the now established formula, we see that we can now show $P(|\hat{p}-p|\leq \epsilon) \geq 1 - P(B)\geq 1-\delta$. This is equivalent to $P(B) \leq \delta$. Since we have an upper bound on $P(B)$ we can use this to calculate $k$ to fulfil this requirement by rewriting the formula
\begin{equation*}
    \begin{split}
        P(B)\leq 2e^{-2k\epsilon^2}&\leq \delta\\
       \Leftrightarrow k&\geq -\frac{1}{2\epsilon^2}\ln{\frac{\delta}{2}}
    \end{split}
\end{equation*}
This is exactly the $k$ we defined in our algorithm. Therefore this proves that our algorithm fulfils the requirements and calculates a good enough estimator $\hat{p}$.

% \bibliographystyle{IEEEtran}
% \bibliography{main}


\end{document}